{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cloud Storage tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJqVsuDRi_x",
        "colab_type": "text"
      },
      "source": [
        "## Storage introduction\n",
        "\n",
        "Cloud storage is a globally unified, scalable, and highly durable object storage system. We could store our data or files of any objects into the bucket. \n",
        "\n",
        "Key features:\n",
        "* Manage storage costs and performance with OLM\n",
        "* Globle location with low latency\n",
        "* Any workload\n",
        "\n",
        "  * Standard - Optimized for performance and high frequency access.\n",
        "  * Nearline - Fast, highly durable, for data accessed less than once a month.\n",
        "  * Coldline - Fast, highly durable, for data accessed less than once a quarter.\n",
        "  * Archive - Most cost-effective, for data accessed less than once a year.\n",
        "  * etc\n",
        "\n",
        "There is a sample use case of storage for machine learning:\n",
        "![Machine learning with storage](https://cloudx-bricks-prod-bucket.storage.googleapis.com/159d98095e3d589068d6267b0861564b7a0bf2aca5c81208989c64662811b517.svg)\n",
        "\n",
        "\n",
        " Let start with data storage with command line also with python code to show use case of cloud storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFkP714YT-Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's first auth user\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3ZtR5lSWWw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b00744f3-40cd-44d2-e219-ab16b3837dc9"
      },
      "source": [
        "# let's set our project\n",
        "! gcloud config set project cloudtutorial-279003"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8uk14MWjee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "0458da81-138a-4462-ac51-44a2dc3361e8"
      },
      "source": [
        "# let's list the region that we could use with bucket\n",
        "! gcloud compute regions list"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME                     CPUS  DISKS_GB  ADDRESSES  RESERVED_ADDRESSES  STATUS  TURNDOWN_DATE\n",
            "asia-east1               0/8   0/2048    0/4        0/8                 UP\n",
            "asia-east2               0/8   0/2048    0/4        0/8                 UP\n",
            "asia-northeast1          0/8   0/2048    0/4        0/8                 UP\n",
            "asia-northeast2          0/8   0/2048    0/4        0/8                 UP\n",
            "asia-northeast3          0/8   0/2048    0/4        0/8                 UP\n",
            "asia-south1              0/8   0/2048    0/4        0/8                 UP\n",
            "asia-southeast1          0/8   0/2048    0/4        0/8                 UP\n",
            "australia-southeast1     0/8   0/2048    0/4        0/8                 UP\n",
            "europe-north1            0/8   0/2048    0/4        0/8                 UP\n",
            "europe-west1             0/8   0/2048    0/4        0/8                 UP\n",
            "europe-west2             0/8   0/2048    0/4        0/8                 UP\n",
            "europe-west3             0/8   0/2048    0/4        0/8                 UP\n",
            "europe-west4             0/8   0/2048    0/4        0/8                 UP\n",
            "europe-west6             0/8   0/2048    0/4        0/8                 UP\n",
            "northamerica-northeast1  0/8   0/2048    0/4        0/8                 UP\n",
            "southamerica-east1       0/8   0/2048    0/4        0/8                 UP\n",
            "us-central1              0/8   2/2048    0/4        0/8                 UP\n",
            "us-east1                 0/8   0/2048    0/4        0/8                 UP\n",
            "us-east4                 0/8   0/2048    0/4        0/8                 UP\n",
            "us-west1                 0/8   0/2048    0/4        0/8                 UP\n",
            "us-west2                 0/8   0/2048    0/4        0/8                 UP\n",
            "us-west3                 0/8   0/2048    0/4        0/8                 UP\n",
            "us-west4                 0/8   0/2048    0/4        0/8                 UP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVymcnDCW747",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef40a524-9879-4955-8284-e71157d96eed"
      },
      "source": [
        "# let's list our bucket\n",
        "# with command, we could just use `gsutil`\n",
        "! gsutil ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://dataflow_tutorial_bucket/\n",
            "gs://new_bucket_for_test/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMgrXTO7XGR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "180a6fd2-b011-497b-d121-a8c7f6839ed3"
      },
      "source": [
        "# let's create a bucket\n",
        "! gsutil mb gs://new_bucket_for_test"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating gs://new_bucket_for_test/...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIaqWsjSXXhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edfdc404-3685-4716-b77d-645d015e84e2"
      },
      "source": [
        "# check\n",
        "! gsutil ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://dataflow_tutorial_bucket/\n",
            "gs://new_bucket_for_test/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RUFZrOmX-5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "17765db9-7916-4eb8-edca-c257b073654d"
      },
      "source": [
        "# let's copy files into the new bucket\n",
        "# -r will recursively copy all files and directories from one bucket to another.\n",
        "# -p will ensure the same permissions for new bucket\n",
        "! gsutil cp -r -p gs://dataflow_tutorial_bucket/* gs://new_bucket_for_test/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://dataflow_tutorial_bucket/data_flow_inputs/<Bucket: dataflow_tutorial_bucket> [Content-Type=data_flow_inputs/<Bucket: dataflow_tutorial_bucket>]...\n",
            "Copying gs://dataflow_tutorial_bucket/data_flow_inputs/sample.txt [Content-Type=data_flow_inputs/sample.txt]...\n",
            "Copying gs://dataflow_tutorial_bucket/data_flow_output/outputs-00000-of-00003 [Content-Type=text/plain]...\n",
            "Copying gs://dataflow_tutorial_bucket/data_flow_output/outputs-00001-of-00003 [Content-Type=text/plain]...\n",
            "\\ [4 files][  1.9 KiB/  1.9 KiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://dataflow_tutorial_bucket/data_flow_output/outputs-00002-of-00003 [Content-Type=text/plain]...\n",
            "Copying gs://dataflow_tutorial_bucket/spark_code/training_spark.py [Content-Type=text/x-python]...\n",
            "| [6 files][  3.0 KiB/  3.0 KiB]                                                \n",
            "Operation completed over 6 objects/3.0 KiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY64Dr2eYHes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f4df96c-0418-4db0-ccd9-0dce9997525b"
      },
      "source": [
        "# let's check the lifecycle of bucket\n",
        "! gsutil lifecycle get gs://new_bucket_for_test"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://new_bucket_for_test/ has no lifecycle configuration.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE_uQZWjpQZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fe249a0-e618-4991-a023-e944c23315a6"
      },
      "source": [
        "#  as we haven't set any lifecycle of the bucket, let's set with a json file, \n",
        "# we could set the bucket file to be 7 days.\n",
        "%%writefile filecycle.json\n",
        "\n",
        "{\n",
        "\"rule\":\n",
        "[\n",
        "{\n",
        "\"action\": {\"type\": \"Delete\"},\n",
        "\"condition\": {\"age\": 7}\n",
        "}\n",
        "]\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting filecycle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLx1XKD6rlVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8814970d-7ee3-45aa-9c21-5bbc0088f700"
      },
      "source": [
        "! gsutil lifecycle set filecycle.json gs://new_bucket_for_test"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting lifecycle configuration on gs://new_bucket_for_test/...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4HoTLSDsxT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63dc25cd-25b4-49b0-a7cd-19ae18d3f87c"
      },
      "source": [
        "# let's check again\n",
        "! gsutil lifecycle get gs://new_bucket_for_test"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"rule\": [{\"action\": {\"type\": \"Delete\"}, \"condition\": {\"age\": 7}}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-sKEyWjs00R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b58cfc17-3e8d-4b4f-9f05-288b62301542"
      },
      "source": [
        "# let's get the detail info about the bucket\n",
        "# -L means detail information\n",
        "# -b means with bucket name specified.\n",
        "! gsutil list -L -b gs://new_bucket_for_test"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://new_bucket_for_test/ :\n",
            "\tStorage class:\t\t\tSTANDARD\n",
            "\tLocation type:\t\t\tmulti-region\n",
            "\tLocation constraint:\t\tUS\n",
            "\tVersioning enabled:\t\tNone\n",
            "\tLogging configuration:\t\tNone\n",
            "\tWebsite configuration:\t\tNone\n",
            "\tCORS configuration: \t\tNone\n",
            "\tLifecycle configuration:\tPresent\n",
            "\tRequester Pays enabled:\t\tNone\n",
            "\tLabels:\t\t\t\tNone\n",
            "\tDefault KMS key:\t\tNone\n",
            "\tTime created:\t\t\tThu, 04 Jun 2020 04:43:08 GMT\n",
            "\tTime updated:\t\t\tThu, 04 Jun 2020 05:01:05 GMT\n",
            "\tMetageneration:\t\t\t2\n",
            "\tBucket Policy Only enabled:\tFalse\n",
            "\tACL:\t\t\t\t\n",
            "\t  [\n",
            "\t    {\n",
            "\t      \"entity\": \"project-owners-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"owners\"\n",
            "\t      },\n",
            "\t      \"role\": \"OWNER\"\n",
            "\t    },\n",
            "\t    {\n",
            "\t      \"entity\": \"project-editors-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"editors\"\n",
            "\t      },\n",
            "\t      \"role\": \"OWNER\"\n",
            "\t    },\n",
            "\t    {\n",
            "\t      \"entity\": \"project-viewers-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"viewers\"\n",
            "\t      },\n",
            "\t      \"role\": \"READER\"\n",
            "\t    }\n",
            "\t  ]\n",
            "\tDefault ACL:\t\t\t\n",
            "\t  [\n",
            "\t    {\n",
            "\t      \"entity\": \"project-owners-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"owners\"\n",
            "\t      },\n",
            "\t      \"role\": \"OWNER\"\n",
            "\t    },\n",
            "\t    {\n",
            "\t      \"entity\": \"project-editors-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"editors\"\n",
            "\t      },\n",
            "\t      \"role\": \"OWNER\"\n",
            "\t    },\n",
            "\t    {\n",
            "\t      \"entity\": \"project-viewers-227224402169\",\n",
            "\t      \"projectTeam\": {\n",
            "\t        \"projectNumber\": \"227224402169\",\n",
            "\t        \"team\": \"viewers\"\n",
            "\t      },\n",
            "\t      \"role\": \"READER\"\n",
            "\t    }\n",
            "\t  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXj67dDpuB6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "846a8c1f-55dd-49c4-9ee8-10b217358d7a"
      },
      "source": [
        "# let's upload a file into the bucket\n",
        "import os\n",
        "\n",
        "with open(\"test.txt\", 'w') as f:\n",
        "  f.write(\"try with gsutil upload file logic\")\n",
        "\n",
        "# when we upload file, we could even don't need to create folder first, \n",
        "# will create folder automatically.\n",
        "! gsutil cp test.txt gs://new_bucket_for_test/upload_file/test.txt"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://test.txt [Content-Type=text/plain]...\n",
            "/ [1 files][   33.0 B/   33.0 B]                                                \n",
            "Operation completed over 1 objects/33.0 B.                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCgggxzYyCVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "884e8122-d8be-42ab-88fa-788c57c83f00"
      },
      "source": [
        "# let's check with the new created folder, we do upload our file into bucket\n",
        "! gsutil ls  gs://new_bucket_for_test/upload_file/ "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://new_bucket_for_test/upload_file/test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SPT32qayXbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "31ee177c-becf-4012-91c6-3eccec91928c"
      },
      "source": [
        "# let's move file\n",
        "! gsutil move gs://new_bucket_for_test/upload_file/test.txt gs://dataflow_tutorial_bucket/upload_file/\n",
        "\n",
        "# so we do move the file from one to the other.\n",
        "! gsutil ls gs://dataflow_tutorial_bucket/upload_file/"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://new_bucket_for_test/upload_file/test.txt [Content-Type=text/plain]...\n",
            "/ [0 files][    0.0 B/   33.0 B]                                                \r/ [1 files][   33.0 B/   33.0 B]                                                \rRemoving gs://new_bucket_for_test/upload_file/test.txt...\n",
            "\n",
            "Operation completed over 1 objects/33.0 B.                                       \n",
            "gs://dataflow_tutorial_bucket/upload_file/test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixAIwGUK2Z-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "70a560e6-1410-409a-cffd-7793765686f0"
      },
      "source": [
        "# let's remove the bucket\n",
        "! gsutil rm -r  gs://new_bucket_for_test"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing gs://new_bucket_for_test/data_flow_inputs/<Bucket: dataflow_tutorial_bucket>#1591245805764858...\n",
            "Removing gs://new_bucket_for_test/data_flow_inputs/sample.txt#1591245806105696...\n",
            "Removing gs://new_bucket_for_test/data_flow_output/outputs-00000-of-00003#1591245806503658...\n",
            "Removing gs://new_bucket_for_test/data_flow_output/outputs-00001-of-00003#1591245807002360...\n",
            "/ [4 objects]                                                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m rm ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Removing gs://new_bucket_for_test/data_flow_output/outputs-00002-of-00003#1591245807286814...\n",
            "Removing gs://new_bucket_for_test/spark_code/training_spark.py#1591245807726618...\n",
            "/ [6 objects]                                                                   \n",
            "Operation completed over 6 objects.                                              \n",
            "Removing gs://new_bucket_for_test/...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCF3aOgY1oB1",
        "colab_type": "text"
      },
      "source": [
        "## Cloud storage with Python\n",
        "\n",
        "As we have already used command line to do common actions of buckets, let's try to use Python client to manage bucket, as when we interact with bucket, we will use client more frequently. \n",
        "\n",
        "Let's start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYUMi6dIy0_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first we have to install the client\n",
        "! pip install google-cloud-storage --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RissjNuk2JT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init client\n",
        "from google.cloud import storage\n",
        "\n",
        "project_id = \"cloudtutorial-279003\"\n",
        "# config with project_id\n",
        "client = storage.Client(project_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5SB3Zd21Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's create a bucket\n",
        "from google.cloud.storage import Bucket\n",
        "\n",
        "bucket = client.create_bucket('bucket_with_python')\n",
        "assert isinstance(bucket, Bucket)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es8ZzDRC3EUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "93b8d2d9-d33f-4ae8-d2f7-f8fc9e8da99a"
      },
      "source": [
        "# here are many functions that we could use with bucket\n",
        "print(dir(bucket))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['COLDLINE_STORAGE_CLASS', 'DUAL_REGION_LOCATION_TYPE', 'DURABLE_REDUCED_AVAILABILITY_LEGACY_STORAGE_CLASS', 'MULTI_REGIONAL_LEGACY_STORAGE_CLASS', 'MULTI_REGION_LOCATION_TYPE', 'NEARLINE_STORAGE_CLASS', 'REGIONAL_LEGACY_STORAGE_CLASS', 'REGION_LOCATION_TYPE', 'STANDARD_STORAGE_CLASS', '_LOCATION_TYPES', '_MAX_OBJECTS_FOR_ITERATION', '_STORAGE_CLASSES', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_acl', '_changes', '_client', '_default_object_acl', '_encryption_headers', '_label_removals', '_location', '_patch_property', '_properties', '_query_params', '_require_client', '_set_properties', '_user_project', 'acl', 'add_lifecycle_delete_rule', 'add_lifecycle_set_storage_class_rule', 'blob', 'clear_lifecyle_rules', 'client', 'configure_website', 'copy_blob', 'cors', 'create', 'default_event_based_hold', 'default_kms_key_name', 'default_object_acl', 'delete', 'delete_blob', 'delete_blobs', 'disable_logging', 'disable_website', 'enable_logging', 'etag', 'exists', 'generate_signed_url', 'generate_upload_policy', 'get_blob', 'get_iam_policy', 'get_logging', 'iam_configuration', 'id', 'labels', 'lifecycle_rules', 'list_blobs', 'list_notifications', 'location', 'location_type', 'lock_retention_policy', 'make_private', 'make_public', 'metageneration', 'name', 'notification', 'owner', 'patch', 'path', 'path_helper', 'project_number', 'reload', 'rename_blob', 'requester_pays', 'retention_period', 'retention_policy_effective_time', 'retention_policy_locked', 'self_link', 'set_iam_policy', 'storage_class', 'test_iam_permissions', 'time_created', 'update', 'user_project', 'versioning_enabled']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAku4hCo3Ra5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1393b422-5ab0-4785-d420-3e1ccca1a040"
      },
      "source": [
        "# let's upload file into bucket\n",
        "blob = bucket.blob('test.txt')\n",
        "try:\n",
        "  blob.upload_from_filename('test.txt')\n",
        "  print('file uploaded')\n",
        "except Exception as e:\n",
        "  print(\"When upload file with error:\", e)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file uploaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZLoUFj3TJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e1434ce-7199-434b-dad9-9b59ea38e436"
      },
      "source": [
        "# let's download the file into local \n",
        "try:\n",
        "  blob.download_to_filename('new_test.txt')\n",
        "  print(\"download file list: \", os.listdir('.'))\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download file list:  ['.config', 'adc.json', 'new_test.txt', 'test.txt', 'filecycle.json', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E93AfbLM4X_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03c5f062-1a15-43f3-e13c-c1937017e9d1"
      },
      "source": [
        "# we could also download the file as a string for later use\n",
        "try:\n",
        "  file_content = blob.download_as_string()\n",
        "  # return is a byte object. One more thing, if we need to upload the file into bucket, we have to \n",
        "  # serialize the data with bytes, so storage is platform independent.\n",
        "  print(\"Get file content:\", file_content)\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get file content: b'try with gsutil upload file logic'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_RHovhO4oKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b840fe30-14da-4a99-cf9e-4ce43add87d8"
      },
      "source": [
        "# after we have created the bucket, we could get the bucket object\n",
        "bucket = client.get_bucket('bucket_with_python')\n",
        "\n",
        "# list bucket files\n",
        "# return is an iterator object\n",
        "blobs = bucket.list_blobs()\n",
        "print(\"file list:\", list(blobs))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file list: [<Blob: bucket_with_python, test.txt, 1591249755726832>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsxy7upl5ZvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78fe8d70-5971-4625-c4da-c0744c1b7910"
      },
      "source": [
        "# let's list the bucket we have\n",
        "print(\"bucket list: \", list(client.list_buckets()))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bucket list:  [<Bucket: bucket_with_python>, <Bucket: dataflow_tutorial_bucket>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC-qJ_rk6Oaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60c57746-06ba-4b16-8e1d-b274b7f81e85"
      },
      "source": [
        "# let's copy one file from one bucket into another\n",
        "source_bucket = client.bucket('dataflow_tutorial_bucket')\n",
        "des_bucket = client.bucket('bucket_with_python')\n",
        "\n",
        "blob_file = source_bucket.blob('upload_file/test.txt')\n",
        "\n",
        "# we could rename the destination file name with `new_name`\n",
        "new_blob = source_bucket.copy_blob(blob_file, des_bucket, new_name='upload_file/new_rename.txt')\n",
        "\n",
        "print(list(des_bucket.list_blobs()))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<Blob: bucket_with_python, test.txt, 1591249755726832>, <Blob: bucket_with_python, upload_file/new_rename.txt, 1591250710306730>, <Blob: bucket_with_python, upload_file/test.txt, 1591250647254400>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djRePPZm7bfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4d9242f-fb15-48b6-d1ff-016ee7eb3a34"
      },
      "source": [
        "# let's delete the file \n",
        "des_bucket.delete_blob('upload_file/new_rename.txt')\n",
        "\n",
        "# check current bucket file, so that we do remove the file in that bucket.\n",
        "print(list(des_bucket.list_blobs()))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<Blob: bucket_with_python, test.txt, 1591249755726832>, <Blob: bucket_with_python, upload_file/test.txt, 1591250647254400>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HIcIhZg84rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc3a8be0-42fe-422f-f108-4497032e075c"
      },
      "source": [
        "# we could check the file exist or not in bucket,\n",
        "# if the file doesn't exist will return None\n",
        "print(des_bucket.get_blob('test.txt'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Blob: bucket_with_python, test.txt, 1591249755726832>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ94ZUK0CBuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13446c61-e768-4548-9b67-4a2ddf77a2a9"
      },
      "source": [
        "# let's delete the bucket\n",
        "try:\n",
        "  # when there are files, we have to force the delete command try to delete whole files, then deletel bucket\n",
        "  # otherwise will face with error: not empty.\n",
        "  des_bucket.delete(force=True)\n",
        "  print(\"bucket has been deleted\")\n",
        "  print(\"current bucket list:\", list(client.list_buckets()))\n",
        "except Exception as e:\n",
        "  raise Exception(\"When delete bucket with error:\", e)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bucket has been deleted\n",
            "current bucket list: [<Bucket: dataflow_tutorial_bucket>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_JLqSgA8ZA_",
        "colab_type": "text"
      },
      "source": [
        "## Final words\n",
        "\n",
        "I have to say that there are many useful functions that we could use for cloud storage, I have just mentioned some common use case, if you are curious about the whole functions, you could find the [API here](https://googleapis.dev/python/storage/latest/buckets.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtnQrds18KIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}