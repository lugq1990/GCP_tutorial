{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI platform optimizer.ipynb","provenance":[],"authorship_tag":"ABX9TyMTgv9nNimwrbfPf1gtswme"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LJSadR47MGZx","colab_type":"text"},"source":["## Get started with AI Plat-form with optimizer\n","\n","When I first heard of the optimizer, I would think out is auto-ml, but this optimizer isn't exactly with auto-ml, it will just get the model best hyper-parameters, why do we need the optimizer? I think if you are an expert in ML, then you would do that manually to find the best parameters based on data, but the production is for someone don't want to tune the models, but just want to get a better result...\n","\n","So the main logic here is first we define our hyper-parameters space, then will use some algorithms to find the best suit parameters, means `best` is not true, no matter what algorithms couldn't do that!\n","\n","There are many strategy could be used like Grid-search, Random-search, Bayes-optimizer, etc. For google cloud implementation uses [Bayes-optimization](https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview#how_hyperparameter_tuning_works), this is high level overview, if you are curious about the detail logic, could find it [here](https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-cloud-machine-learning-engine-using-bayesian-optimization).\n","\n","Currently during the code implemetation, I found optimizer needs you to provide the min and max space for the hyper-parameters, that's to reduce the  search space by mind. But I have to say that there do add so many codes.... That's why GCP is for developers:)? "]},{"cell_type":"code","metadata":{"id":"f3I0vcsqPuNJ","colab_type":"code","outputId":"549a74f8-2090-47ae-c476-7df071857d5b","executionInfo":{"status":"ok","timestamp":1590641989033,"user_tz":-480,"elapsed":14773,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# install the libraries we need\n","! pip install -U google-api-python-client google-cloud --quiet\n","! pip install -U google-cloud-storage  --quiet\n","! pip install -U requests --quiet\n","! pip install google-cloud-api-python --quiet"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement google-cloud-api-python (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for google-cloud-api-python\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qngJOX-pP8Zt","colab_type":"code","outputId":"37abcc40-88e1-497a-bdb7-e1581fd302c6","executionInfo":{"status":"ok","timestamp":1590649205438,"user_tz":-480,"elapsed":4057,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# config the project\n","! gcloud config set project cloudtutorial-278306"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXrAyz5FRWrS","colab_type":"code","colab":{}},"source":["# auth the notebook\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1NV8-1tSFkT","colab_type":"text"},"source":["## setup parameters for optimizer"]},{"cell_type":"code","metadata":{"id":"SmLiJXq0SSQy","colab_type":"code","colab":{}},"source":["import json\n","import time\n","import datetime\n","from googleapiclient import errors\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zp0T5-uhR6wW","colab_type":"code","colab":{}},"source":["USER = 'lugq'\n","\n","STUDY_ID = \"{}_study_{}\".format(USER, datetime.datetime.now().strftime('%Y%m%d'))\n","REGION = 'us-central1'\n","\n","PROJECT_ID = \"cloudtutorial-278306\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s59FwaTuSxVL","colab_type":"code","outputId":"4190c0b5-e837-4885-f03e-ad9701037b9b","executionInfo":{"status":"ok","timestamp":1590646654406,"user_tz":-480,"elapsed":59,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["def study_parent():\n","  return \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n","\n","def study_name(study_id):\n","  return 'projects/{}/locations/{}/studies/{}'.format(PROJECT_ID, REGION, study_id)\n","\n","def trial_parent(study_id):\n","  return study_name(study_id)\n","\n","def trial_name(study_id, trial_id):\n","  return 'projects/{}/locations/{}/studies/{}/trials/{}'.format(PROJECT_ID, REGION, study_id, trial_id)\n","\n","def operation_name(operation_id):\n","  return 'projects/{}/locations/{}/operations/{}'.format(PROJECT_ID, REGION, operation_id)\n","\n","\n","print('USER: {}'.format(USER))\n","print('PROJECT_ID: {}'.format(PROJECT_ID))\n","print('REGION: {}'.format(REGION))\n","print('STUDY_ID: {}'.format(STUDY_ID))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["USER: lugq\n","PROJECT_ID: cloudtutorial-278306\n","REGION: us-central1\n","STUDY_ID: lugq_study_20200528\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cp22YXIsS-VF","colab_type":"code","outputId":"cc13332e-4cd2-49ca-9a4c-fdcf40c452f7","executionInfo":{"status":"ok","timestamp":1590642252464,"user_tz":-480,"elapsed":2001,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# then we need to upload the file into bucket\n","from google.cloud import storage\n","from googleapiclient import discovery\n","\n","# this is a public bucket that we could use for optimizer, not own bucket.\n","optimizer_bucket = 'caip-optimizer-public'\n","optimizer_file = 'api/ml_public_google_rest_v1.json'\n","\n","def read_api_document():\n","  client = storage.Client(PROJECT_ID)\n","  bucket = client.get_bucket(optimizer_bucket)\n","  blob = bucket.get_blob(optimizer_file)\n","  return blob.download_as_string()\n","\n","ml = discovery.build_from_document(service=read_api_document())\n","print('build client')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["build client\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VrR-80WwrLeL","colab_type":"text"},"source":["## Define parameters space\n","\n","Then we should try to optimize the the hyper-parameters, but currently is for build-in algorithms. For user algorithm, will try to find out."]},{"cell_type":"code","metadata":{"id":"hiya-tToqZdj","colab_type":"code","outputId":"0c382778-6289-4036-afe6-bbd61969064e","executionInfo":{"status":"ok","timestamp":1590643174263,"user_tz":-480,"elapsed":1390,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":673}},"source":["# this is json configuration of seach space\n","learning_rate_space = {\n","    'parameter': 'learning_rate', \n","    'type': 'double',\n","    'double_value_spec':{\n","        'min_value': .0001,\n","        'max_value': 1.0\n","    },\n","    'scale_type': 'unit_log_scale',    # how to sample config parameters. \n","    'parent_categorical_values':{\n","        'values': ['linear']\n","    }\n","}\n","\n","# model config\n","param_model_type = {\n","    'parameter': 'model_type',\n","    'type': 'categorical',\n","    'categorical_value_spec': {'values': ['linear']},\n","    'child_parameter_specs': [learning_rate_space]\n","}\n","\n","# metrics\n","metric_accuracy = {\n","    'metric': 'accuracy',\n","    'goal': \"maximize\"\n","}\n","\n","# define our study config\n","study_config = {\n","    'algorithm': 'algorithm_unspecified',    # not to set, let service to find\n","    'parameters': [param_model_type,],\n","    'metrics': [metric_accuracy,]\n","}\n","\n","study = {'study_config': study_config}\n","\n","# let's see what we have made.... So many parameter with wrap\n","print(json.dumps(study, indent=2, sort_keys=True))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{\n","  \"study_config\": {\n","    \"algorithm\": \"algorithm_unspecified\",\n","    \"metrics\": [\n","      {\n","        \"goal\": \"maximize\",\n","        \"metric\": \"accuracy\"\n","      }\n","    ],\n","    \"parameters\": [\n","      {\n","        \"categorical_value_spec\": {\n","          \"values\": [\n","            \"linear\"\n","          ]\n","        },\n","        \"child_parameter_specs\": [\n","          {\n","            \"double_value_spec\": {\n","              \"max_value\": 1.0,\n","              \"min_value\": 0.0001\n","            },\n","            \"parameter\": \"learning_rate\",\n","            \"parent_categorical_values\": {\n","              \"values\": [\n","                \"linear\"\n","              ]\n","            },\n","            \"scale_type\": \"unit_log_scale\",\n","            \"type\": \"double\"\n","          }\n","        ],\n","        \"parameter\": \"model_type\",\n","        \"type\": \"categorical\"\n","      }\n","    ]\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AFEUB4R0qeZX","colab_type":"code","outputId":"7fb6f462-13a8-4e57-fc6b-54d63d8f9cf8","executionInfo":{"status":"ok","timestamp":1590643175017,"user_tz":-480,"elapsed":1590,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# then we could create our study object\n","# I have to say that with so many configuration dictionary, will always raise 400 error \n","# for not recognize the parameter.... I think this should make it into function as function\n","# parameters, then we don't need to write so many json....\n","\n","req = ml.projects().locations().studies().create(parent=study_parent(), \n","                                                     studyId=STUDY_ID, body=study)\n","\n","try:\n","  print(req.execute())\n","except errors.HttpError as e:\n","  if e.resp.status == '409':\n","    print('study already created')\n","  else:\n","    raise e"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'name': 'projects/574974437586/locations/us-central1/studies/lugq_study_20200528', 'studyConfig': {'metrics': [{'goal': 'MAXIMIZE', 'metric': 'accuracy'}], 'parameters': [{'parameter': 'model_type', 'type': 'CATEGORICAL', 'categoricalValueSpec': {'values': ['linear']}, 'childParameterSpecs': [{'parameter': 'learning_rate', 'type': 'DOUBLE', 'doubleValueSpec': {'minValue': 0.0001, 'maxValue': 1}, 'scaleType': 'UNIT_LOG_SCALE', 'parentCategoricalValues': {'values': ['linear']}}]}]}, 'state': 'ACTIVE', 'createTime': '2020-05-28T05:19:34Z'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kSEVsWQ9W5mc","colab_type":"text"},"source":["## Configuration\n","\n","The most important thing I found with optimizer is that there isn't a processing step in fact, we just load data from bucket, so the optimizer step will assume that preprocessing step has finished and save final result as a file into bucket or even big query. \n","\n","Also this is really a tough way to make the whole thing done, as this is not a local server, it's remote container, even with just prepreparing will take at least 2 mins, when we do face error in code, it will about 4 mins.... "]},{"cell_type":"code","metadata":{"id":"BINynlJ3trX9","colab_type":"code","outputId":"bab43393-109d-43eb-b63c-e080a8573fed","executionInfo":{"status":"ok","timestamp":1590654431499,"user_tz":-480,"elapsed":1132,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# after we have already created the study object, then we should \n","# config where to output the config result, that's to the bucket...\n","output_bucket = 'first_bucket_lugq'\n","output_dir = 'optimizer_test'\n","\n","# Here I think I have to chenge data with label as first column and without columns name...\n","training_data_path = \"gs://{}/sklearn_tutorial/data_label_first.csv\".format(output_bucket)\n","\n","\n","print(\"Where to get data:\", training_data_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Where to get data: gs://first_bucket_lugq/sklearn_tutorial/data_label_first.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H4feXfUQv7xg","colab_type":"code","colab":{}},"source":["# then we will evaluate the model based on each trial step,\n","# will write a summary file into bucket as `final_measurement`\n","# but we have to write our log function by ourself.\n","import logging\n","import math\n","import subprocess\n","import os\n","import yaml\n","\n","logging.basicConfig(level=logging.INFO)\n","\n","training_job_name_pattern = '{}_condition_parameters_{}_{}'\n","\n","# as we will use build-in algorithm, we should define our image location...\n","image_urls = {'linear': 'gcr.io/cloud-ml-algos/linear_learner_cpu:latest'}\n","_step_count = 'step_count'\n","_accuracy = 'accuracy'\n","\n","def evaluate_trials(trials):\n","  trials_by_job_id = {}\n","  mesurement_by_trial_id = {}\n","\n","  # Submits a AI Platform Training job for each trial.\n","  for trial in trials:\n","    trial_id = int(trial['name'].split('/')[-1])\n","    model_type = get_suggest_param_value(trial, 'model_type', 'stringValue')\n","    learning_rate = get_suggest_param_value(trial, 'learning_rate', 'floatValue')\n","\n","    job_id = generate_training_job_id(model_type, trial_id)\n","\n","    # make the trial config\n","    trials_by_job_id[job_id] = {\n","        'trial_id': trial_id,\n","        'model_type': model_type,\n","        'learning_rate': learning_rate,\n","    }\n","\n","    # then we could submit our job...\n","    submit_job(job_id, trial_id, model_type, learning_rate)\n","\n","  # then we could wait for the training step finish\n","  # if and only if the whole job has finished, we could move on.\n","  while not is_job_complete(trials_by_job_id.keys()):\n","    time.sleep(5)\n","\n","  # get the training result\n","  logging.info(\"start to get the job metrics...\")\n","  metrics_by_job_id = get_job_metrics(trials_by_job_id.keys())\n","\n","  # get measurement for accuracy\n","  logging.info(\"Metrics has finished, get metrics object:\", metrics_by_job_id.items())\n","  for job_id, metric in metrics_by_job_id.items():\n","    measurement = create_measurement(trials_by_job_id[job_id]['trial_id'],\n","                                     trials_by_job_id[job_id]['model_type'],\n","                                     trials_by_job_id[job_id]['learning_rate'],\n","                                     metric)\n","    mesurement_by_trial_id[trials_by_job_id[job_id]['trial_id']] = measurement\n","    return  mesurement_by_trial_id\n","\n","\n","def get_suggest_param_value(trial, parameter,  value_type):\n","  # get suggested parameters values by parameter and type.\n","  param_found = [p for p in trial['parameters'] if p['parameter'] == parameter]\n","  if param_found:\n","    logging.info(\"Get suggestion value: \", str(param_found[0][value_type]))\n","    return param_found[0][value_type]\n","  else:\n","    return None\n","\n","\n","def generate_training_job_id(model_type, trial_id):\n","  # define a name of job\n","  return training_job_name_pattern.format(STUDY_ID, model_type, trial_id)\n","\n","\n","def get_training_state(job_id):\n","  # this is to get the current job status with command\n","  cmd = ['gcloud', 'ai-platform', 'jobs', 'describe', job_id,\n","         '--project', PROJECT_ID,\n","         '--format', 'json']\n","  try:\n","    output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, timeout=3)\n","\n","    logging.info(\"Get training status:\", json.loads(output)['state'])\n","    return json.loads(output)['state']\n","  except subprocess.CalledProcessError as e:\n","    logging.error(e.output)\n","  \n","\n","\n","def is_job_complete(jobs):\n","  # check given jobs have completed or not.\n","  all_done = True\n","  for job in jobs:\n","    if get_training_state(job) not in  ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n","      all_done = False\n","\n","  logging.info(\"All jobs have been done.\")\n","  return all_done\n","\n","\n","def get_job_dir(job_id):\n","  # this is really like if we do auto-ml training, we would seperate each model with temperate folder...\n","  return os.path.join('gs://', output_bucket, output_dir, job_id)\n","\n","\n","def linear_command(job_id, learning_rate):\n","  # this is used to submit linear training job....\n","  return ['gcloud', 'ai-platform', 'jobs', 'submit', 'training', job_id,\n","         '--scale-tier', 'BASIC',\n","          '--region', 'us-central1',\n","          '--master-image-uri', image_urls['linear'],\n","          '--project', PROJECT_ID,\n","         # '--job-dir', get_job_dir(job_id),   # we do need to set the job-dir, otherwise will face error.\n","          # I'm not sure why I give a full in gs, will always raise error for: ValueError: Bucket names must start and end with a number or letter.\n","          '--job-dir', \"gs://{}/sklearn_tutorial/output\".format(output_bucket),   # dir must be a url start with gs://\n","          '--',\n","          '--preprocess',\n","          '--model_type=classification',    # this is common parameters setting for training like batch size etc.\n","          '--batch_size=250',\n","          '--max_steps=1000',\n","          '--learning_rate={}'.format(learning_rate),\n","          '--training_data_path={}'.format(training_data_path)\n","          ]\n","\n","\n","def get_accuracy(job_id):\n","  # this is to get trained model accuracy with build-in algorithm\n","  client = storage.Client(PROJECT_ID)\n","  bucket = client.get_bucket(output_bucket)\n","  blob_name = os.path.join(output_dir, job_id, 'model/deployment_config.yaml')\n","  blob = storage.Blob(blob_name, bucket)\n","\n","  # what we do is to get the file content with bucket\n","  try:\n","    blob.reload()\n","    content = blob.download_as_string()\n","    accuracy = float(yaml.safe_load(content)['labels']['accuracy']) / 100\n","    step_count = int(yaml.safe_load(content)['labels']['global_step'])\n","    return {_step_count: step_count, _accuracy: accuracy}\n","  except:\n","    return None\n","\n","\n","def get_job_metrics(jobs):\n","  # this is to get the whole jobs metrics\n","  accuracies_by_job_id = {}\n","  for job in jobs:\n","    accuracies_by_job_id[job] = get_accuracy(job)\n","  \n","  logging.info(\"Get accuracy dictionary:\", str(accuracies_by_job_id))\n","  return accuracies_by_job_id\n","\n","\n","def create_measurement(trial_id, model_type, learning_rate, metric):\n","  # this is to get measurement of of job....\n","  if metric is None:\n","    logging.error(\"Get a empty metric!!!!\")\n","  else:\n","    if not metric[_accuracy]:\n","      return None\n","    else:\n","      measurement = {\n","        _step_count: metric[_step_count],\n","        'metrics': [{'metric': _accuracy, 'value': metric[_accuracy]},]}\n","    \n","      # logging.info(\"Get measurement:\", str(measurement))\n","      return measurement\n","        \n","\n","def submit_job(job_id, trial_id, model_type, learning_rate):\n","  # this is to submit job with command line.\n","  try:\n","    if model_type == 'linear':\n","      subprocess.check_output(linear_command(job_id, learning_rate), stderr=subprocess.STDOUT)\n","    else:\n","      logging.error('not support')\n","  except subprocess.CalledProcessError as e:\n","    logging.error(e.output)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvuwgPag5YTb","colab_type":"code","colab":{}},"source":["client_id = 'client12' \n","suggestion_count_per_request =   1\n","max_trial_id_to_stop =   1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXdwn3OS6HcC","colab_type":"code","outputId":"35de81ba-fe7d-4632-8f59-d8284bdfed01","executionInfo":{"status":"ok","timestamp":1590656654914,"user_tz":-480,"elapsed":276824,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["current_trial_id = 0\n","while current_trial_id < max_trial_id_to_stop:\n","  # Request trials\n","  resp = ml.projects().locations().studies().trials().suggest(\n","    parent=trial_parent(STUDY_ID), \n","    body={'client_id': client_id, 'suggestion_count': suggestion_count_per_request}).execute()\n","  op_id = resp['name'].split('/')[-1]\n","\n","  # Polls the suggestion long-running operations.\n","  get_op = ml.projects().locations().operations().get(name=operation_name(op_id))\n","  while True:\n","      operation = get_op.execute()\n","      if 'done' in operation and operation['done']:\n","        break\n","      time.sleep(1)\n","\n","  # Featches the suggested trials.\n","  trials = []\n","  for suggested_trial in get_op.execute()['response']['trials']:\n","    trial_id = int(suggested_trial['name'].split('/')[-1])\n","    trial = ml.projects().locations().studies().trials().get(name=trial_name(STUDY_ID, trial_id)).execute()\n","    if trial['state'] not in ['COMPLETED', 'INFEASIBLE']:\n","      print(\"Trial {}: {}\".format(trial_id, trial))\n","      trials.append(trial)\n","\n","  # Evaluates trials - Submit model training jobs using AI Platform Training built-in algorithms.\n","  measurement_by_trial_id = evaluate_trials(trials)\n","  \n","  # I even forget to update the step...\n","  current_trial_id += 1\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Trial 14: {'name': 'projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/14', 'state': 'ACTIVE', 'parameters': [{'parameter': 'model_type', 'stringValue': 'linear'}, {'parameter': 'learning_rate', 'floatValue': 0.011290392048492156}], 'startTime': '2020-05-28T08:59:40Z', 'clientId': 'client12'}\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n","ERROR:root:Get a empty metric!!!!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5VQKCUygUs1q","colab_type":"code","outputId":"68e1f350-a6aa-4f26-e4e9-2d8d28ba1ec3","executionInfo":{"status":"ok","timestamp":1590656705477,"user_tz":-480,"elapsed":1171,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Completes trials.\n","for trial in trials:\n","  trial_id = int(trial['name'].split('/')[-1])\n","  current_trial_id = trial_id\n","  measurement = measurement_by_trial_id[trial_id]\n","  print((\"=========== Complete Trial: [{0}] =============\").format(trial_id))\n","  if measurement:\n","    # Completes trial by reporting final measurement.\n","    ml.projects().locations().studies().trials().complete(\n","      name=trial_name(STUDY_ID, trial_id), \n","      body={'final_measurement' : measurement}).execute()\n","  else:\n","    # Marks trial as `infeasbile` if when missing final measurement.\n","    ml.projects().locations().studies().trials().complete(\n","      name=trial_name(STUDY_ID, trial_id), \n","      body={'trial_infeasible' : True}).execute()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["=========== Complete Trial: [14] =============\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cPt17X7tEYoP","colab_type":"code","outputId":"bd3c2b96-c8ae-4271-f180-fe4cae4d02bf","executionInfo":{"status":"ok","timestamp":1590656709159,"user_tz":-480,"elapsed":1150,"user":{"displayName":"guangqiang lu","photoUrl":"","userId":"05333431788560706430"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# final step is to list the rial result\n","resp = ml.projects().locations().studies().trials().list(parent=trial_parent(STUDY_ID)).execute()\n","print(json.dumps(resp, indent=2, sort_keys=True))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{\n","  \"trials\": [\n","    {\n","      \"clientId\": \"client1\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/1\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.010000000000000005,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T06:14:20Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client1\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/2\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.0036307811788057714,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T06:14:20Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client2\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/3\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.001202264644745583,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:04:14Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client2\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/4\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.03311310845024023,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:04:14Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client3\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/5\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.12022639855694754,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:15:57Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client4\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/6\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.47862949469167154,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:35:03Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client5\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/7\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.0002754229189478068,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:40:54Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client6\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/8\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.0001,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T07:46:55Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client7\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/9\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 1,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:06:37Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client8\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/10\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.01123581957120447,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:16:40Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client9\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/11\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.011784293035990497,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:27:27Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client10\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/12\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.01084810667806139,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:43:03Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client11\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/13\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.011171192238975404,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:53:44Z\",\n","      \"state\": \"ACTIVE\"\n","    },\n","    {\n","      \"clientId\": \"client12\",\n","      \"endTime\": \"2020-05-28T09:04:15Z\",\n","      \"name\": \"projects/574974437586/locations/us-central1/studies/lugq_study_20200528/trials/14\",\n","      \"parameters\": [\n","        {\n","          \"parameter\": \"model_type\",\n","          \"stringValue\": \"linear\"\n","        },\n","        {\n","          \"floatValue\": 0.011290392048492156,\n","          \"parameter\": \"learning_rate\"\n","        }\n","      ],\n","      \"startTime\": \"2020-05-28T08:59:40Z\",\n","      \"state\": \"COMPLETED\",\n","      \"trialInfeasible\": true\n","    }\n","  ]\n","}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"02AEqkj5gnou","colab_type":"text"},"source":["## Show results\n","\n","As we have already done the whole logic with optimizer, how to check the result? Maybe first is to check that the checkpoint of model and some metrics that is conducted, so we could first to get the [job summary](https://console.cloud.google.com/ai-platform/jobs?project=cloudtutorial-278306), the log is also here, one more thing is that is also support to output a **Tensorboard summary** that we could get info about the model structure etc. The other thing is the output is saved in bucket, we could also check that [bucket objects](https://console.cloud.google.com/storage/browser/first_bucket_lugq/sklearn_tutorial/?forceOnBucketsSortingFiltering=false&project=cloudtutorial-278306)."]},{"cell_type":"markdown","metadata":{"id":"tSKpy0LTfSzL","colab_type":"text"},"source":["## Final wods\n","\n","I have to say there are toooo many codes that I have to write, to config, to test to make the whole thing done, if possible, I won't use this product util the logic is wrapped into the package to easy to use. \n","\n","The main thing is to find the great hyper-parameter that suit best for data, why not to use other algorithms to find the sub-best parameters? Even what we do will also get sub-best parameters, that won't that tough than to use current solution..."]},{"cell_type":"code","metadata":{"id":"vDxkpybJgIm0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}